# -------- grafana -----------------------------
rbac:
  create: true
  pspEnabled: true
serviceAccount:
  create: true
  name:

replicas: 1

deploymentStrategy: RollingUpdate

readinessProbe:
  httpGet:
    path: /api/health
    port: 3000

livenessProbe:
  httpGet:
    path: /api/health
    port: 3000
  initialDelaySeconds: 60
  timeoutSeconds: 30
  failureThreshold: 10

image:
  repository: grafana/grafana
  tag: 5.3.2
  pullPolicy: IfNotPresent

  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  # pullSecrets:
  #   - myRegistrKeySecretName

securityContext:
  runAsUser: 472
  fsGroup: 472

downloadDashboardsImage:
  repository: appropriate/curl
  tag: latest
  pullPolicy: IfNotPresent

## Pod Annotations
# podAnnotations: {}

## Deployment annotations
# annotations: {}

## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).
## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.
## ref: http://kubernetes.io/docs/user-guide/services/
##
service:
  # DISABLED # type: ClusterIP
  # In a production setup, we recommend accessing Grafana through an external Loadbalancer
  # or through a public IP.
  # type: LoadBalancer
  # You could also use NodePort to expose the service at a randomly-generated port
  # type: NodePort
  type: NodePort
  port: 80
  # DISABLED # annotations: {}
  annotations:
    # SOURCE: https://github.com/nginxinc/kubernetes-ingress/tree/master/examples/multiple-ingress-controllers
    # NOTE: To designate that a particular Ingress resource must be handled only by the NGINX or NGINX Plus controller add the following annotation along with the value to the Ingress resource:
    kubernetes.io/ingress.class: "nginx"
    kubernetes.io/tls-acme: "false"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    # Note the nginx.ingress.kubernetes.io/ssl-redirect annotation. It is used since we are not specifying a host. When no host is specified, then the default-server is hit, which is configured with a self-signed certificate, and redirects http to https. This issue explains more.
    # https://github.com/kubernetes/ingress-nginx/issues/1567
    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"
    # SOURCE: https://medium.com/@Oskarr3/setting-up-ingress-on-minikube-6ae825e98f82
    nginx.ingress.kubernetes.io/rewrite-target: /
  #   kubernetes.io/ingress.class: nginx
  #   kubernetes.io/tls-acme: 'true'
  # DISABLED # labels: {}
  labels:
    task: monitoring
    k8s-app: grafana

ingress:
  enabled: true
  # annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  annotations:
    # SOURCE: https://github.com/nginxinc/kubernetes-ingress/tree/master/examples/multiple-ingress-controllers
    # NOTE: To designate that a particular Ingress resource must be handled only by the NGINX or NGINX Plus controller add the following annotation along with the value to the Ingress resource:
    kubernetes.io/ingress.class: "nginx"
    kubernetes.io/tls-acme: "false"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    # Note the nginx.ingress.kubernetes.io/ssl-redirect annotation. It is used since we are not specifying a host. When no host is specified, then the default-server is hit, which is configured with a self-signed certificate, and redirects http to https. This issue explains more.
    # https://github.com/kubernetes/ingress-nginx/issues/1567
    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"
    # SOURCE: https://medium.com/@Oskarr3/setting-up-ingress-on-minikube-6ae825e98f82
    nginx.ingress.kubernetes.io/rewrite-target: /
  #   kubernetes.io/ingress.class: nginx
  #   kubernetes.io/tls-acme: 'true'
  labels: {}
  path: /
  hosts:
    - grafana.scarlettlab.home
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - grafana.scarlettlab.home

# DISABLED # resources: {}
resources:
 limits:
   cpu: 100m
   memory: 128Mi
 requests:
   cpu: 100m
   memory: 128Mi

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
#
nodeSelector: {}

## Tolerations for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []

## Affinity for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
# FIXME: look into this, does it work?
# persistence:
#   enabled: true
#   storageClassName: default
#   accessModes:
#     - ReadWriteOnce
#   size: 10Gi
#   annotations: {}
#   subPath: ""
#   existingClaim:
# FIXME: pod has unbound PersistentVolumeClaims
# SOURCE: https://stackoverflow.com/questions/52668938/pod-has-unbound-persistentvolumeclaims
persistence:
  ## If true, Grafana server will create/use a Persistent Volume Claim
  ## If false, use emptyDir
  ##
  enabled: true

  ## Grafana server data Persistent Volume access modes
  ## Must match those of existing PV or dynamic provisioner
  ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  accessModes:
    - ReadWriteOnce

  ## Grafana server data Persistent Volume annotations
  ##
  annotations: {}

  ## Grafana server data Persistent Volume existing claim name
  ## Requires server.persistentVolume.enabled: true
  ## If defined, PVC must be created manually before volume will be bound
  existingClaim:

  ## Grafana server data Persistent Volume size
  ##
  size: 10Gi

  # Another example: "nfs-provisioner"
  # SOURCE: https://github.com/choerodon/website/blob/c6007070feabea453a47c781d308cf35e20ef60c/content/docs/installation-configuration/steps/operation/monitoring.md
  # NOTE: A PersistentVolume without StorageClass is considered to be static. "Dynamic Volume Provisioning" alongside with a StorageClass allows the cluster to provision PersistentVolumes on demand. In order to make that work, the given storage provider must support provisioning - it will then allow the cluster to request the provisioning of a "new" PersistentVolume when an unsatisfied PersistentVolumeClaim pops up.
  # storageClassName: default

  ## Grafana server data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"

  ## Subdirectory of Grafana server data Persistent Volume to mount
  ## Useful if the volume's root directory is not empty
  ##
  subPath: ""

adminUser: admin
adminPassword: password

## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

## Extra environment variables that will be pass onto deployment pods
env: {}
# SOURCE: https://github.com/kubernetes/heapster/blob/master/deploy/kube-config/influxdb/grafana.yaml
# env:
#   - name: INFLUXDB_HOST
#     value: boss-monitoring-influxdb
#   - name: GF_SERVER_HTTP_PORT
#     value: "3000"
#     # The following env variables are required to make Grafana accessible via
#     # the kubernetes api-server proxy. On production clusters, we recommend
#     # removing these env variables, setup auth for grafana, and expose the grafana
#     # service using a LoadBalancer or a public IP.
#   - name: GF_AUTH_BASIC_ENABLED
#     value: "false"
#   - name: GF_AUTH_ANONYMOUS_ENABLED
#     value: "true"
#   - name: GF_AUTH_ANONYMOUS_ORG_ROLE
#     value: Admin
#   - name: GF_SERVER_ROOT_URL
#     # If you're only using the API Server proxy, set this value instead:
#     # value: /api/v1/namespaces/kube-system/services/monitoring-grafana/proxy
#     value: /

## The name of a secret in the same kubernetes namespace which contain values to be added to the environment
## This can be useful for auth tokens, etc
envFromSecret: ""

## Additional grafana server secret mounts
# Defines additional mounts with secrets. Secrets must be manually created in the namespace.
extraSecretMounts: []
  # - name: secret-files
  #   mountPath: /etc/secrets
  #   secretName: grafana-secret-files
  #   readOnly: true

## Pass the plugins you want installed as a list.
##
# DISABLED # plugins: []
plugins:
  - briangann-datatable-panel
  - btplc-alarm-box-panel
  - cloudflare-app
  - digiapulssi-breadcrumb-panel
  - digrich-bubblechart-panel
  - grafana-clock-panel
  - grafana-piechart-panel
  - grafana-worldmap-panel
  - jdbranham-diagram-panel
  - mtanda-heatmap-epoch-panel
  - mtanda-histogram-panel
  - natel-discrete-panel
  - natel-plotly-panel
  - neocat-cal-heatmap-panel
  - novalabs-annotations-panel
  - petrslavotinek-carpetplot-panel
  - raintank-worldping-app
  - vonage-status-panel

## Configure grafana datasources
## ref: http://docs.grafana.org/administration/provisioning/#datasources
##
datasources: {}
# TODO: Enable all of this
# datasources:
#   apiVersion: 1
#   datasources:
#     - name: InfluxDB
#       type: influxdb
#       access: proxy
#       url: http://influxdb:8086
#       user: devnet
#       password: create
#       database: ezdash
#       isDefault: true
#     - name: ElasticSearch
#       type: elasticsearch
#       access: proxy
#       url: http://elasticsearch:9200
#       user: elastic
#       password: changeme
#       database: metricbeat-*
#       jsonData:
#         esVersion: "56"
#         timeField: "@timestamp"
#         timeInterval: "5s"
#     - name: Prometheus
#       type: prometheus
#       access: proxy
#       url: http://prometheus:9090
#  datasources.yaml:
#    apiVersion: 1
#    datasources:
#    - name: Prometheus
#      type: prometheus
#      url: http://prometheus-prometheus-server
#      access: proxy
#      isDefault: true

# TODO: Another data source example
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: sample-grafana-datasource
#   labels:
#      grafana_datasource: 1
# data:
#   datasource.yaml: |-
#     # config file version
#     apiVersion: 1

#     # list of datasources that should be deleted from the database
#     deleteDatasources:
#       - name: Graphite
#         orgId: 1

#     # list of datasources to insert/update depending
#     # whats available in the database
#     datasources:
#       # <string, required> name of the datasource. Required
#     - name: Graphite
#       # <string, required> datasource type. Required
#       type: graphite
#       # <string, required> access mode. proxy or direct (Server or Browser in the UI). Required
#       access: proxy
#       # <int> org id. will default to orgId 1 if not specified
#       orgId: 1
#       # <string> url
#       url: http://localhost:8080
#       # <string> database password, if used
#       password:
#       # <string> database user, if used
#       user:
#       # <string> database name, if used
#       database:
#       # <bool> enable/disable basic auth
#       basicAuth:
#       # <string> basic auth username
#       basicAuthUser:
#       # <string> basic auth password
#       basicAuthPassword:
#       # <bool> enable/disable with credentials headers
#       withCredentials:
#       # <bool> mark as default datasource. Max one per org
#       isDefault:
#       # <map> fields that will be converted to json and stored in json_data
#       jsonData:
#          graphiteVersion: "1.1"
#          tlsAuth: true
#          tlsAuthWithCACert: true
#       # <string> json object of data that will be encrypted.
#       secureJsonData:
#         tlsCACert: "..."
#         tlsClientCert: "..."
#         tlsClientKey: "..."
#       version: 1
#       # <bool> allow users to edit datasources from the UI.
#       editable: false

## Configure grafana dashboard providers
## ref: http://docs.grafana.org/administration/provisioning/#dashboards
##
## `path` must be /var/lib/grafana/dashboards/<provider_name>
##
# DISABLED # dashboardProviders: {}
dashboardProviders:
 dashboardproviders.yaml:
   apiVersion: 1
   providers:
   - name: 'default'
     orgId: 1
     folder: ''
     type: file
     disableDeletion: false
     editable: true
     options:
       path: /var/lib/grafana/dashboards/default

## Configure grafana dashboard to import
## NOTE: To use dashboards you must also enable/configure dashboardProviders
## ref: https://grafana.com/dashboards
##
## dashboards per provider, use provider name as key.
##
dashboards: {}
#  default:
#    some-dashboard:
#      json: |
#        $RAW_JSON
#    prometheus-stats:
#      gnetId: 2
#      revision: 2
#      datasource: Prometheus
#    local-dashboard:
#      url: https://example.com/repository/test.json

## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.
## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.
## ConfigMap data example:
##
## data:
##   example-dashboard.json: |
##     RAW_JSON
##
dashboardsConfigMaps: {}
#  default: ""

## Grafana's primary configuration
## NOTE: values in map will be converted to ini format
## ref: http://docs.grafana.org/installation/configuration/
##
grafana.ini:
  paths:
    data: /var/lib/grafana/data
    logs: /var/log/grafana
    plugins: /var/lib/grafana/plugins
    provisioning: /etc/grafana/provisioning
  analytics:
    check_for_updates: true
  log:
    mode: console
  grafana_net:
    # FIXME: idk if this works or not
    url: https://grafana.net
## LDAP Authentication can be enabled with the following values on grafana.ini
## NOTE: Grafana will fail to start if the value for ldap.toml is invalid
  # auth.ldap:
  #   enabled: true
  #   allow_sign_up: true
  #   config_file: /etc/grafana/ldap.toml

## Grafana's LDAP configuration
## Templated by the template in _helpers.tpl
## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled
## ref: http://docs.grafana.org/installation/configuration/#auth-ldap
## ref: http://docs.grafana.org/installation/ldap/#configuration
ldap:
  # `existingSecret` is a reference to an existing secret containing the ldap configuration
  # for Grafana in a key `ldap-toml`.
  existingSecret: ""
  # `config` is the content of `ldap.toml` that will be stored in the created secret
  config: ""
  # config: |-
  #   verbose_logging = true

  #   [[servers]]
  #   host = "my-ldap-server"
  #   port = 636
  #   use_ssl = true
  #   start_tls = false
  #   ssl_skip_verify = false
  #   bind_dn = "uid=%s,ou=users,dc=myorg,dc=com"

## Grafana's SMTP configuration
## NOTE: To enable, grafana.ini must be configured with smtp.enabled
## ref: http://docs.grafana.org/installation/configuration/#smtp
smtp:
  # `existingSecret` is a reference to an existing secret containing the smtp configuration
  # for Grafana in keys `user` and `password`.
  existingSecret: ""

## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders
## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards
sidecar:
  image: kiwigrid/k8s-sidecar:0.0.3
  imagePullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 100m
      memory: 100Mi
    requests:
      cpu: 50m
      memory: 50Mi
  dashboards:
    enabled: true
    # label that the configmaps with dashboards are marked with
    label: grafana_dashboard
    # folder in the pod that should hold the collected dashboards
    folder: /tmp/dashboards
  datasources:
    enabled: true
    # label that the configmaps with datasources are marked with
    label: grafana_datasource
